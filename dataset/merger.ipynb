{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7799d526-a4c6-403e-847d-feaccba55a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_FEATURES = [\n",
    "    # Flow / packet dynamics\n",
    "    \"disp_pakt\",\n",
    "    \"disp_byte\",\n",
    "    \"mean_pkt\",\n",
    "    \"mean_byte\",\n",
    "\n",
    "    # Flow behavior\n",
    "    \"avg_durat\",\n",
    "    \"avg_flow_dst\",\n",
    "\n",
    "    # Rate-based features (VERY important)\n",
    "    \"rate_pkt_in\",\n",
    "    \"disp_interval\",\n",
    "\n",
    "    # Network / switch context\n",
    "    \"switch_id\",\n",
    "\n",
    "    # Label (always kept)\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "OPTIONAL_FEATURES = [\n",
    "    \"flow_count\",  #controller workload\n",
    "    \"unique_src_ip\",  #spoofing & distribution\n",
    "    \"unique_dst_ip\",  #scanning & amplification\n",
    "    \"packet_in_count\"  #direct controller stress\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3d0f58-0009-436f-82eb-999d3eb51f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged SYN_FLOOD_ATK.csv + UDP_FLOOD_atk.csv\n",
      "Saved → SDN_ATK.csv\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    32955\n",
      "1    12170\n",
      "2     8841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def prepare_dataframe(df, core_features, optional_features):\n",
    "    # 1️⃣ Check core features\n",
    "    missing_core = [f for f in core_features if f not in df.columns]\n",
    "    if missing_core:\n",
    "        raise ValueError(f\"Missing CORE features: {missing_core}\")\n",
    "\n",
    "    # 2️⃣ Add missing optional features as zeros\n",
    "    for f in optional_features:\n",
    "        if f not in df.columns:\n",
    "            df[f] = 0\n",
    "\n",
    "    # 3️⃣ Keep only core + optional\n",
    "    final_features = core_features + optional_features\n",
    "    df = df[final_features]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_two_csvs(\n",
    "    csv1,\n",
    "    csv2,\n",
    "    output_csv,\n",
    "    core_features=CORE_FEATURES,\n",
    "    optional_features=OPTIONAL_FEATURES\n",
    "):\n",
    "    df1 = pd.read_csv(csv1)\n",
    "    df2 = pd.read_csv(csv2)\n",
    "\n",
    "    df1 = prepare_dataframe(df1, core_features, optional_features)\n",
    "    df2 = prepare_dataframe(df2, core_features, optional_features)\n",
    "\n",
    "    merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    merged.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Merged {csv1} + {csv2}\")\n",
    "    print(f\"Saved → {output_csv}\")\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(merged[\"label\"].value_counts())\n",
    "\n",
    "\n",
    "merge_two_csvs(\n",
    "    \"SYN_FLOOD_ATK.csv\",   # first file\n",
    "    \"UDP_FLOOD_atk.csv\",   # second file\n",
    "    \"SDN_ATK.csv\"          # master dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a4fe37a-e17f-4f1d-b835-741aca064d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before change:\n",
      "label\n",
      "0    18352\n",
      "1     8841\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After change:\n",
      "label\n",
      "0    18352\n",
      "2     8841\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved updated file → UDP_FLOOD_atk.csv\n"
     ]
    }
   ],
   "source": [
    "#Label Changer\n",
    "import pandas as pd\n",
    "\n",
    "def change_label(\n",
    "    input_csv,\n",
    "    output_csv,\n",
    "    old_label,\n",
    "    new_label,\n",
    "    label_column=\"label\"\n",
    "):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if label_column not in df.columns:\n",
    "        raise ValueError(f\"'{label_column}' column not found\")\n",
    "\n",
    "    print(f\"Before change:\\n{df[label_column].value_counts()}\\n\")\n",
    "\n",
    "    df[label_column] = df[label_column].replace(old_label, new_label)\n",
    "\n",
    "    print(f\"After change:\\n{df[label_column].value_counts()}\\n\")\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved updated file → {output_csv}\")\n",
    "    \n",
    "# Convert binary ICMP dataset:\n",
    "# 1 (attack) → 2 (ICMP_FLOOD)\n",
    "#change file name and see which label to change to what ist\n",
    "change_label(\n",
    "    input_csv=\"UDP_FLOOD_ATK.csv\",\n",
    "    output_csv=\"UDP_FLOOD_atk.csv\",\n",
    "    old_label=1,\n",
    "    new_label=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cef01fd4-b11b-4de5-b0bb-c50a53432082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved file: MASTER_DATASET_WITH_ATTACK_ID.csv\n",
      "\n",
      "attack_id distribution:\n",
      "attack_id\n",
      "normal       63561\n",
      "SYN flood    40784\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#label and create and atk id for the end of data set\n",
    "\n",
    "#use only after u have created the final dataset of 5 attacks\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# EDIT THIS MAPPING ONLY\n",
    "LABEL_TO_ATTACK_ID = {\n",
    "    0: \"normal\",  # Normal\n",
    "    1: \"SYN flood\",  # SYN Flood\n",
    "    2: \"UDP flood\",  # UDP Flood\n",
    "    3: \"ICMP flood\",  # ICMP Flood (add later if you want)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# SIMPLE FUNCTION\n",
    "# =========================\n",
    "def add_attack_id_column(\n",
    "    input_csv,\n",
    "    output_csv,\n",
    "    label_column=\"label\",\n",
    "    attack_id_column=\"attack_id\"\n",
    "):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Map labels to attack IDs\n",
    "    df[attack_id_column] = df[label_column].map(LABEL_TO_ATTACK_ID)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    print(\"Saved file:\", output_csv)\n",
    "    print(\"\\nattack_id distribution:\")\n",
    "    print(df[attack_id_column].value_counts())\n",
    "\n",
    "\n",
    "add_attack_id_column(\n",
    "    input_csv=\"dataset_sdn.csv\",\n",
    "    output_csv=\"Master_Dataset_SDN.csv\"#remember to keep it no changes here\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39b940-b1c4-4511-9ed6-26fea715e400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
